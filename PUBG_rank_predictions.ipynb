{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PUBG_rank_predictions.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLaHyf7NWmlb",
        "colab_type": "code",
        "outputId": "cdecb818-b575-4704-8072-9412d0c9c409",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEPXwRKrcWOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    # iterate through all the columns of a dataframe and modify the data type\n",
        "    #   to reduce memory usage.        \n",
        "    \n",
        "#     start_mem = df.memory_usage().sum() / 1024**2\n",
        "#     print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "\n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        \n",
        "        col_type = str(df[col].dtype)\n",
        "        if col_type == 'object':\n",
        "            col_type = 'str'\n",
        "        else:\n",
        "            col_type = 'np.' + col_type\n",
        "\n",
        "#     end_mem = df.memory_usage().sum() / 1024**2\n",
        "#     print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "#     print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqvuUV0aXkIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pubg_data = pd.read_csv('/content/drive/My Drive/DL_final_project/pubg-finish-placement-prediction/train_V2.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_udntrRX3iz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pubg_data = reduce_mem_usage(pubg_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQIsZ5aavJf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVDCCddudVom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pubg_data = pubg_data.fillna(0).reset_index(drop = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YC7hG4odoEV",
        "colab_type": "code",
        "outputId": "5b27541f-d29e-4333-ee6c-b3f52d83294f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pubg_data_oh = pd.concat([pubg_data,pd.get_dummies(pubg_data['matchType'])],axis = 1)\n",
        "del pubg_data\n",
        "gc.collect()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGMLBCSfil8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pubg_data_sample = pubg_data_oh.sample(frac = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDl3Ngg4bR5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perf_features(X,train=False):\n",
        "    X['headshot_rate'] = X['headshotKills'] / (X['kills'] + 0.0001)\n",
        "    X['kill_streak_rate'] = X['killStreaks'] / (X['kills'] + 0.0001)\n",
        "    X['kills_assists'] = X['kills'] + X['assists']\n",
        "    X['heals_boosts'] = X['heals'] + X['boosts']\n",
        "    X['total_distance'] = X['walkDistance'] + X['rideDistance'] + X['swimDistance']\n",
        "    X['totalDistance_weaponsAcq_Ratio'] = X['total_distance'] / (X['weaponsAcquired'] + 1)\n",
        "    X['walkDistance_heals_Ratio'] = X['walkDistance'] / (X['heals'] + 1)\n",
        "    X['walkDistance_kills_Ratio'] = X['walkDistance'] / (X['kills'] + 0.0001)\n",
        "    X['kills_walkDistance_Ratio'] = X['kills'] / (X['walkDistance'] + 0.0001)\n",
        "    X['kills_assists_per_heal_boost'] = X['kills_assists'] / (X['heals_boosts'] + 1)\n",
        "    X['damageDealt_per_heal_boost'] = X['damageDealt'] / (X['heals_boosts'] + 1)\n",
        "    X['road_kills_per_rideDistance'] = X['roadKills'] / (X['rideDistance'] + 0.0001)\n",
        "    X['maxPlace_per_numGroups'] = X['maxPlace'] /( X['numGroups'] + 1 )\n",
        "    X['assists_per_kill'] = X['assists'] / (X['kills'] + X['assists'] + 0.0001)\n",
        "    X['killPlace'] = X['killPlace'] - 1\n",
        "    X['total_Distance_Per_Duration'] =  X[\"total_distance\"]/(X[\"matchDuration\"] + 0.0001)\n",
        "    X['walk_Distance_Per_Duration'] =  X[\"walkDistance\"]/(X[\"matchDuration\"] + 0.0001)\n",
        "    X['kills_Per_Duration'] =  X[\"kills\"]/(X[\"matchDuration\"] + 0.0001)\n",
        "    X[X == np.Inf] = np.NaN\n",
        "    X[X == np.NINF] = np.NaN\n",
        "    X.fillna(0, inplace=True)\n",
        "\n",
        "    data = X\n",
        "    feature = list(data.columns)\n",
        "    feature.remove('Id')\n",
        "    feature.remove('groupId')\n",
        "    feature.remove('matchId')\n",
        "    feature.remove('matchType')\n",
        "    if(train):\n",
        "      labels = np.array(data.groupby(['matchId','groupId'])['winPlacePerc'].agg('mean'), dtype=np.float64)\n",
        "      feature.remove('winPlacePerc')\n",
        "    else: \n",
        "      labels = data[['Id']]\n",
        "    \n",
        "    print(\"group_max\")\n",
        "    agg = data.groupby(['matchId','groupId'])[feature].agg('max')\n",
        "    agg_rank = agg.groupby('matchId')[feature].rank(pct=True).reset_index()\n",
        "    if train: data_out = agg.reset_index()[['matchId','groupId']]\n",
        "    else: data_out = data[['matchId','groupId']]\n",
        "    data_out = data_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId','groupId'])\n",
        "    data_out = data_out.merge(agg_rank, suffixes=[\"_max\", \"_max_rank\"], how='left', on=['matchId','groupId'])\n",
        "    \n",
        "    print(\"group_mean\")\n",
        "    agg = data.groupby(['matchId','groupId'])[feature].agg('mean')\n",
        "    agg_rank = agg.groupby('matchId')[feature].rank(pct=True).reset_index()\n",
        "    data_out = data_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId','groupId'])\n",
        "    data_out = data_out.merge(agg_rank, suffixes=[\"_mean\", \"_mean_rank\"], how='left', on=['matchId','groupId'])\n",
        "    \n",
        "    print(\"group_min\")\n",
        "    agg = data.groupby(['matchId','groupId'])[feature].agg('min')\n",
        "    agg_rank = agg.groupby('matchId')[feature].rank(pct=True).reset_index()\n",
        "    data_out = data_out.merge(agg.reset_index(), suffixes=[\"\", \"\"], how='left', on=['matchId','groupId'])\n",
        "    data_out = data_out.merge(agg_rank, suffixes=[\"_min\", \"_min_rank\"], how='left', on=['matchId','groupId'])\n",
        "    \n",
        "    print(\"match_mean\")\n",
        "    agg = data.groupby(['matchId'])[feature].agg('mean').reset_index()\n",
        "    data_out = data_out.merge(agg, suffixes=[\"\", \"_match_mean\"], how='left', on=['matchId'])\n",
        "    \n",
        "    print(\"match_max\")\n",
        "    agg = data.groupby(['matchId'])[feature].agg('max').reset_index()\n",
        "    data_out = data_out.merge(agg, suffixes=[\"\", \"_match_max\"], how='left', on=['matchId'])\n",
        "    \n",
        "    print(\"match_size\")\n",
        "    agg = data.groupby(['matchId']).size().reset_index(name='match_size')\n",
        "    data_out = data_out.merge(agg, how='left', on=['matchId'])\n",
        "    \n",
        "\n",
        "    del data,agg,agg_rank\n",
        "    gc.collect()\n",
        "    data_out.drop([\"matchId\", \"groupId\"], axis=1, inplace=True)\n",
        "\n",
        "    #data_out = reduce_size(data_out)\n",
        "    X = data_out\n",
        "    del data_out, feature\n",
        "    gc.collect()\n",
        "    return X,labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTDnEVLteDC4",
        "colab_type": "code",
        "outputId": "419c8dc3-41a4-4d12-dd7b-4da8f3d41561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "#X = pubg_data_oh.drop(['Id','groupId','matchId','matchType','winPlacePerc'],axis =1)\n",
        "#features = list(X.columns)\n",
        "#y = pubg_data_oh['winPlacePerc'].values\n",
        "X,y = perf_features(pubg_data_oh,True)\n",
        "del pubg_data_oh\n",
        "gc.collect()\n",
        "#X_sample = pubg_data_sample.drop(['Id','groupId','matchId','matchType','winPlacePerc'],axis =1).values\n",
        "#y_sample = pubg_data_sample['winPlacePerc'].values\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "group_max\n",
            "group_mean\n",
            "group_min\n",
            "match_mean\n",
            "match_max\n",
            "match_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7FeacJmZjhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# from sklearn.preprocessing import  MinMaxScaler\n",
        "# mm= MinMaxScaler()\n",
        "# X= mm.fit_transform(X)\n",
        "# y = y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9ESIxtOX-5l",
        "colab_type": "code",
        "outputId": "2932fd44-854e-4871-95fb-38dabed4ab38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "del X,y\n",
        "gc.collect()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzpRJtI1uo1h",
        "colab_type": "code",
        "outputId": "ebbabb55-1363-48e1-f37a-c9c1c5da1897",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "reg = LinearRegression()\n",
        "reg.fit(X_train,y_train)\n",
        "y_pred = reg.predict(X_test)\n",
        "del reg\n",
        "gc.collect()\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "mean_absolute_error(y_pred,y_test)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.04154452298007842"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrKN8-vsupHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lightgbm as lgb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svW0OwhTupK1",
        "colab_type": "code",
        "outputId": "5fffa44a-a0af-4df8-92d3-7ba74039516f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "lgb_train = lgb.Dataset(X_train, y_train)\n",
        "lgb_eval = lgb.Dataset(X_test, y_test)\n",
        "# specify your configurations as a dict\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'mae',\n",
        "    'num_leaves': 150,\n",
        "    'learning_rate': 0.05,\n",
        "    'num_threads':4,\n",
        "    'min_split_gain':0.0002,\n",
        "    'bagging_fraction': 0.5,\n",
        "    \"bagging_seed\" : 0,\n",
        "    'min_data_in_leaf':2000, \n",
        "    'verbose': 0,\n",
        "    \"colsample_bytree\" : 0.5,\n",
        "    'lamda_l2':8\n",
        "}\n",
        "print('Starting training...')\n",
        "# train\n",
        "gbm = lgb.train(params,\n",
        "                lgb_train,\n",
        "                num_boost_round=2000,\n",
        "                valid_sets=[lgb_train,lgb_eval],\n",
        "                verbose_eval=100,\n",
        "                early_stopping_rounds=20)\n",
        "\n",
        "del lgb_train,lgb_eval\n",
        "gc.collect()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "Training until validation scores don't improve for 20 rounds.\n",
            "[100]\ttraining's l1: 0.0323617\tvalid_1's l1: 0.0326145\n",
            "[200]\ttraining's l1: 0.0293886\tvalid_1's l1: 0.0297861\n",
            "[300]\ttraining's l1: 0.0281615\tvalid_1's l1: 0.0286921\n",
            "[400]\ttraining's l1: 0.0273798\tvalid_1's l1: 0.0280432\n",
            "[500]\ttraining's l1: 0.0268098\tvalid_1's l1: 0.0276064\n",
            "[600]\ttraining's l1: 0.0263686\tvalid_1's l1: 0.0272999\n",
            "[700]\ttraining's l1: 0.0260017\tvalid_1's l1: 0.0270591\n",
            "[800]\ttraining's l1: 0.0256917\tvalid_1's l1: 0.0268759\n",
            "[900]\ttraining's l1: 0.0254062\tvalid_1's l1: 0.0267094\n",
            "[1000]\ttraining's l1: 0.0251453\tvalid_1's l1: 0.0265654\n",
            "[1100]\ttraining's l1: 0.0249211\tvalid_1's l1: 0.026459\n",
            "[1200]\ttraining's l1: 0.0247006\tvalid_1's l1: 0.0263498\n",
            "[1300]\ttraining's l1: 0.0244982\tvalid_1's l1: 0.026261\n",
            "[1400]\ttraining's l1: 0.024309\tvalid_1's l1: 0.0261842\n",
            "[1500]\ttraining's l1: 0.024118\tvalid_1's l1: 0.0260983\n",
            "[1600]\ttraining's l1: 0.0239426\tvalid_1's l1: 0.0260285\n",
            "[1700]\ttraining's l1: 0.0237736\tvalid_1's l1: 0.0259684\n",
            "[1800]\ttraining's l1: 0.0236129\tvalid_1's l1: 0.0259139\n",
            "[1900]\ttraining's l1: 0.0234548\tvalid_1's l1: 0.0258564\n",
            "[2000]\ttraining's l1: 0.0233035\tvalid_1's l1: 0.0258072\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[2000]\ttraining's l1: 0.0233035\tvalid_1's l1: 0.0258072\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "372"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeUrsArqPlZF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "17db4f2e-5fd7-41e9-8e3c-51b769b69b00"
      },
      "source": [
        "print('Starting predicting...')\n",
        "# predict\n",
        "\n",
        "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
        "mean_absolute_error(y_pred,y_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting predicting...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.025807159395492454"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWkR4XRyOo2E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "580e0dff-eaf5-450a-d27d-b563768cfd7f"
      },
      "source": [
        "features = X_train.columns\n",
        "featureImp = list(gbm.feature_importance())\n",
        "featureImp, features = zip(*sorted(zip(featureImp, features)))\n",
        "feature_imp_dict = {}\n",
        "for i in range(len(featureImp)):\n",
        "    feature_imp_dict[features[i]] =  featureImp[i]\n",
        "del gbm\n",
        "gc.collect()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmD680ZOxVoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "\n",
        "sorted_dict = collections.OrderedDict(feature_imp_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTpeMwPxym23",
        "colab_type": "code",
        "outputId": "6fa9b990-31ee-447b-b79b-0ee529993b30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "count_feature_0 = 0\n",
        "#print(sorted_dict)\n",
        "for items in list(sorted_dict.items()):\n",
        "  #print(items)\n",
        "  if(items[1] == 0):\n",
        "    count_feature_0 = count_feature_0 + 1\n",
        "\n",
        "print(count_feature_0)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdVap2eW3Eg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "top_half = list(sorted_dict.items())[::-1][0:int(1*len(sorted_dict.items()))]\n",
        "top_half_feat = []\n",
        "\n",
        "for feat in top_half:\n",
        "  top_half_feat.append(feat[0])\n",
        "\n",
        "#top_half_feat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaEyc6FDvg8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eEqJaP9upOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train_feat = X_train[top_half_feat]\n",
        "# X_test_feat = X_test[top_half_feat]\n",
        "\n",
        "# from sklearn.linear_model import LinearRegression\n",
        "# reg = LinearRegression()\n",
        "# reg.fit(X_train_feat,y_train)\n",
        "# y_pred = reg.predict(X_test_feat)\n",
        "# del reg\n",
        "# gc.collect()\n",
        "# from sklearn.metrics import mean_absolute_error\n",
        "# mean_absolute_error(y_pred,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAxZHBvFZz8w",
        "colab_type": "code",
        "outputId": "7addb5e5-850a-460e-dd95-ee544ccd5830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Dense,BatchNormalization,Activation,Dropout, LeakyReLU\n",
        "def build_regressor():\n",
        "    regressor = Sequential()\n",
        "    \n",
        "    regressor.add(Dense(units=256, input_dim=X_train.shape[1]))\n",
        "    regressor.add(BatchNormalization())\n",
        "    regressor.add(LeakyReLU(alpha = 0.1))\n",
        "    regressor.add(Dropout(0.5))\n",
        "    regressor.add(Dense(units=128))\n",
        "    regressor.add(BatchNormalization())\n",
        "    regressor.add(LeakyReLU(alpha = 0.1))\n",
        "    regressor.add(Dropout(0.4))\n",
        "    regressor.add(Dense(units=64))\n",
        "    regressor.add(BatchNormalization())\n",
        "    regressor.add(LeakyReLU(alpha = 0.1))\n",
        "    regressor.add(Dropout(0.3))\n",
        "    regressor.add(Dense(units=1))\n",
        "    regressor.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae'])\n",
        "    return regressor"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWrN-h9pZ3J0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "regressor = KerasRegressor(build_fn=build_regressor, batch_size=64,epochs=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mblHbl4mfBc3",
        "colab_type": "code",
        "outputId": "4abf82cb-6d36-4a44-9522-bc6aa5fcd3c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        }
      },
      "source": [
        "results=regressor.fit(X_train.values,y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "1621396/1621396 [==============================] - 290s 179us/step - loss: 0.0334 - mean_absolute_error: 0.1338\n",
            "Epoch 2/50\n",
            "1621396/1621396 [==============================] - 282s 174us/step - loss: 0.0174 - mean_absolute_error: 0.1039\n",
            "Epoch 3/50\n",
            "1621396/1621396 [==============================] - 291s 180us/step - loss: 0.0156 - mean_absolute_error: 0.0982\n",
            "Epoch 4/50\n",
            "1621396/1621396 [==============================] - 291s 179us/step - loss: 0.0147 - mean_absolute_error: 0.0954\n",
            "Epoch 5/50\n",
            "1621396/1621396 [==============================] - 290s 179us/step - loss: 0.0143 - mean_absolute_error: 0.0937\n",
            "Epoch 6/50\n",
            "1621396/1621396 [==============================] - 289s 179us/step - loss: 0.0140 - mean_absolute_error: 0.0927\n",
            "Epoch 7/50\n",
            "1621396/1621396 [==============================] - 288s 178us/step - loss: 0.0137 - mean_absolute_error: 0.0917\n",
            "Epoch 8/50\n",
            "1621396/1621396 [==============================] - 288s 178us/step - loss: 0.0136 - mean_absolute_error: 0.0912\n",
            "Epoch 9/50\n",
            "1621396/1621396 [==============================] - 289s 178us/step - loss: 0.0134 - mean_absolute_error: 0.0907\n",
            "Epoch 10/50\n",
            "1621396/1621396 [==============================] - 289s 178us/step - loss: 0.0133 - mean_absolute_error: 0.0902\n",
            "Epoch 11/50\n",
            "1005632/1621396 [=================>............] - ETA: 1:49 - loss: 0.0132 - mean_absolute_error: 0.0900Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aag4VgI6Ii0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVrjpnj_fCNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred= regressor.predict(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTr4Wms7kl76",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a13c2fc-c6e2-4deb-9465-e65ba38e1843"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "mean_absolute_error(y_pred,y_test)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07442004981755747"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZqbs_cDlt6H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f042b13-c3b2-4e86-9e8a-639883e1d591"
      },
      "source": [
        "del regressor\n",
        "gc.collect()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYHDS4QsmdSe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "053ea88b-611a-44c6-8078-0b35e39a7504"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "regr = DecisionTreeRegressor(max_depth=100, random_state=0, max_features = 50, max_leaf_nodes=10)\n",
        "regr.fit(X_train, y_train)\n",
        "y_pred = regr.predict(X_test)\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "mean_absolute_error(y_pred,y_test)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08342486858348738"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gra9TVAbo5qM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}